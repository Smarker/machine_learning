{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **supervised** machine learning algorithm\n",
    "* mainly used for **classification** but also could be used in regression\n",
    "* requires **numerical** inputs\n",
    "* performs classification by using **decision boundaries** in a multidimensional space to separate different classes of points\n",
    "* provides the **maximum** separating margin for a **linearly separable** dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Boundary\n",
    "\n",
    "* partitions the underlying vector space into two sets, one for each class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Margin\n",
    "\n",
    "* the **distance** from a **data point** to the **decision boundary**\n",
    "* the goal of a svm is to **maximize** the **margin**\n",
    "\n",
    "In the diagram below, the margin is the distance from $H_n$ to a point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![svm](https://user-images.githubusercontent.com/7232635/45568835-a41e9a00-b855-11e8-97d2-198561880572.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Kernel Trick"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you do **not** have linear separable data necessary for a SVM, you can use the kernel trick. Data that is not linearly separable in lower dimensional space, may be linearly separable in **higher dimensional space**. The kernel trick uses a **kernel** to transform the data into a higher dimensional space, so that the data are linearly separable.\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/7232635/45712860-6a060e80-bb5b-11e8-8d2c-4eb56d84e0ea.png)\n",
    "\n",
    "In summary, the kernel trick is performed by taking the **dot product** of input data points and the kernel, where the result is mapped into the higher dimensional feature space\n",
    "\n",
    "### Examples\n",
    "\n",
    "* linear\n",
    "* radial basis function (rbf) \n",
    "* polynomial\n",
    "* sigmoid"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
